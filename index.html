<html>
  <head>
<!-- 2016 Gordon Williams, gw@pur3.co.uk

Any copyright is dedicated to the Public Domain.
http://creativecommons.org/publicdomain/zero/1.0/

-->
    <meta charset="utf-8">
    <meta name="viewport" content="width=320, initial-scale=1">
    <title>Online Heart Rate Monitor</title>
    <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
    <script type="text/javascript" src="face-api.min.js"></script>
  </head>
  <body>
    <p>Allow this website to use your webcam, then detect your face over the camera and wait for the trace to stabilise.</p>
    <div style="position: relative;">
      <video onloadedmetadata="" id="v" muted></video>
      <canvas style="position: absolute; top: 0px; left: 0px;" id="overlay"></canvas>
    </div>
    
    
    <br/>
    <canvas id="c" width="640" height="480" style="display:none"></canvas>
    <br/>
    
    <canvas id="g" width="320" height="30"></canvas><br/>
    <div id="bpm">--</div>
    <button onclick="pausevideo()">Stop</button>
    <button onclick="playvideo()">Play</button>
    

    <p>Also, check out <a href="http://www.puck-js.com/">Puck.js</a></p>
  <script>
  window.mobileCheck = function() {
let check = false;
(function(a){if(/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(a)||/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0,4))) check = true;})(navigator.userAgent||navigator.vendor||window.opera);
return check;
};
  var video, width, height, context, graphCanvas, graphContext, bpm;
  var hist = [];
  var Forehead, Leftcheek, Rightcheek;
  navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia;
  var time = Date.now || function() {
   return +new Date;
  };
  var constraints = {video: true, audio:false};

  function pausevideo(){
    video.pause();
  }

  function playvideo(){
    video.play();
  }

  async function initialize() {
    MODEL_URL = 'https://justadudewhohacks.github.io/face-api.js/models';
    // faceapi.SsdMobilenetv1Options({ minConfidence })
    // faceapi.nets.ssdMobilenetv1.loadFromUri(modelurl)
    // faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
    // faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
    // faceapi.nets.FaceLandmarkModel.loadFromUri(MODEL_URL),
    
    // faceapi.loadTinyFaceDetectorModel(MODEL_URL)
    // faceapi.loadFaceLandmarkTinyModel(MODEL_URL)
    
    await faceapi.loadFaceLandmarkModel(MODEL_URL)
    await faceapi.loadTinyFaceDetectorModel(MODEL_URL)


    navigator.mediaDevices.enumerateDevices().then(function(devices) {
      devices.forEach(function(device) {
        console.log(device.kind + ": " + device.label +
                    " id = " + device.deviceId/*, JSON.stringify(device,null,2)*/);
        if (device.kind=="videoinput" /*&& constraints.video===true*/)
        if(window.mobileCheck()){
            if (device.label.includes('front')){
                constraints.video = { optional: [{sourceId: device.deviceId}, { fillLightMode: "on" }] };
            }
        }else{
            constraints.video = { optional: [{sourceId: device.deviceId}, { fillLightMode: "on" }] };
        }
      });
      initialize2();
    }).catch(function(err) {
      console.log(err.name + ": " + err.message);
    });
  }

  function initialize2() {
    // The source video.
    video = document.getElementById("v");
    // width = video.width;
    // height = video.height;

    // The target canvas.
    var canvas = document.getElementById("c");
    context = canvas.getContext("2d");

    // The canvas for the graph
    graphCanvas = document.getElementById("g");
    graphContext = graphCanvas.getContext("2d");
 
    // The bpm meter
    bpm = document.getElementById("bpm");
    
    // Get the webcam's stream.
    if (navigator.mediaDevices.getUserMedia) {
      navigator.mediaDevices.getUserMedia(constraints)
        .then(startStream)
        .catch(console.error)
    } else {
      navigator.getUserMedia(constraints, startStream, function () {});
    }
  }

  function startStream(stream) {
    info = stream.getTracks()[0].getSettings();
    $('#overlay').get(0).width = info.width;
    $('#overlay').get(0).height = info.height;
    width = info.width;
    height = info.height;
    console.log(width, height);
    video.srcObject = stream;
    video.play();
    // Ready! Let's start drawing.
    requestAnimationFrame(draw);
  }

  function draw() {
    if(video.paused || video.ended){
      
    }
    else{
      var frame = readFrame()
      if (frame) {
        try {
          detectFace()
          forehead_data = context.getImageData(Forehead[0],Forehead[1],Forehead[2],Forehead[3]).data
          leftcheek_data = context.getImageData(Leftcheek[0],Leftcheek[1],Leftcheek[2],Leftcheek[3]).data
          rightcheek_data = context.getImageData(Rightcheek[0],Rightcheek[1],Rightcheek[2],Rightcheek[3]).data
          data =  new Uint8ClampedArray(forehead_data,leftcheek_data,rightcheek_data)
          getIntensity(data); 
          // getIntensity(frame.data);  
        } catch (e){
          
        }
      }
    }

    // Wait for the next frame.
    requestAnimationFrame(draw);
  }

  function readFrame() {
    try {
      context.drawImage(video, 0, 0, width, height);
    } catch (e) {
      // The video may not be ready, yet.
      return null;
    }

    return context.getImageData(0, 0, width, height);
  }
  
  function getIntensity(data) {
    var len = data.length;
    var sum = 0;
    for (var i = 0, j = 0; j < len; i++, j += 4) {
      sum += data[j] + data[j+1] + data[j+2];
    }
    //console.log(sum / len);   
    hist.push({ bright : sum/len, time : Date.now() });
    while (hist.length>graphCanvas.width) hist.shift();
    // max and min
    var max = hist[0].bright;
    var min = hist[0].bright;
    hist.forEach(function(v) {
      if (v.bright>max) max=v.bright;
      if (v.bright<min) min=v.bright;
    });
    // thresholds for bpm
    var lo = min*0.6 + max*0.4;
    var hi = min*0.4 + max*0.6;
    var pulseAvr = 0, pulseCnt = 0;
    // draw
    var ctx = graphContext;
    ctx.clearRect(0, 0, graphCanvas.width, graphCanvas.height);
    ctx.beginPath();
    ctx.moveTo(0,0);
    hist.forEach(function(v,x) {
      var y = graphCanvas.height*(v.bright-min)/(max-min);
      ctx.lineTo(x,y);
    });       
    ctx.stroke();
    // work out bpm
    var isHi = undefined;
    var lastHi = undefined;
    var lastLo = undefined;
    ctx.fillStyle = "red";
    hist.forEach(function(v, x) {
      if (isHi!=true && v.bright>hi) {
        isHi = true;
        lastLo = x;
      }
      if (isHi!=false && v.bright<lo) {
        if (lastHi !== undefined && lastLo !== undefined) {
          pulseAvr += hist[x].time-hist[lastHi].time;
          pulseCnt++;
          ctx.fillRect(lastLo,graphCanvas.height-4,lastHi-lastLo,4);
        }
        isHi = false;
        lastHi = x;
      }
    });
    // write bpm
    if (pulseCnt) {
      var pulseRate = 60000 / (pulseAvr / pulseCnt);
      bpm.innerHTML = pulseRate.toFixed(0)+" BPM ("+pulseCnt+" pulses)";
    } else {
      bpm.innerHTML = "-- BPM";
    }
  }
  
  addEventListener("DOMContentLoaded", initialize);

  async function detectFace() {

      if(video.paused || video.ended)
        return ;
        // return setTimeout(() => detectFace())

      const inputSize = 512;
      const scoreThreshold = 0.5;
      const OPTION = new faceapi.TinyFaceDetectorOptions({
          inputSize,
          scoreThreshold
      });


      const result = await faceapi.detectSingleFace(video, OPTION).withFaceLandmarks()

      if (result) {
        const top = result.detection.box.top
        const lms = result.landmarks.positions

        const canvas = $('#overlay').get(0)
        var ctx = canvas.getContext("2d")
        ctx.clearRect(0, 0, canvas.width, canvas.height)
        ctx.strokeStyle = "#FF0000";

        Forehead = [lms[18].x, top, -(lms[18].x-lms[25].x), -(top-lms[19].y)*0.6]
        ctx.strokeRect(Forehead[0],Forehead[1],Forehead[2],Forehead[3])

        Leftcheek = [lms[4].x, lms[1].y, lms[48].x-lms[4].x, lms[50].y-lms[1].y]
        ctx.strokeRect(Leftcheek[0],Leftcheek[1],Leftcheek[2],Leftcheek[3])

        Rightcheek = [lms[12].x, lms[15].y, lms[54].x-lms[12].x, lms[52].y-lms[15].y]
        ctx.strokeRect(Rightcheek[0],Rightcheek[1],Rightcheek[2],Rightcheek[3])
        // const dims = faceapi.matchDimensions(canvas, videoEl, true)
        // const resizedResult = faceapi.resizeResults(result, dims)
        // faceapi.draw.drawDetections(canvas, resizedResult)
        // faceapi.draw.drawFaceLandmarks(canvas, resizedResult)
      }

      // setTimeout(() => detectFace())
    }

  </script>
  </body>
</html>
